# SOR unroll DOE

The aim is to see if memory reduction will improve performance of unrolled SOR.
The reference test shows that unrolling by repeated calls to the SOR kernel with intermediate arrays has not benefit in sequential mode.
This is with static allocation. With  WITH_OMP it is faster, about 2x, but DYN_ALLOC makes no difference.

At first sight, memory reduction with static allocation and sequential is much slower.

For UNROLL=4, it's 300x slower, with OpenMP:

memreduced: niters=10  68s
reference: niters=300 6.8s

For UNROLL=3, with OpenMP, it's 40x slower:

memreduced: niters=10  6.4s
reference: niters=400 6.8s

For UNROLL=2, with OpenMP, it's 6x slower:

memreduced: niters=100  8.4s
reference: niters=600 6.8s

The question is if this is still the case for high memory use. Currently, we use about 3MB per array. Let's increase this to at least 300 MB so we use a few GB.

If I increase the array size with 10x for i and j (so 100x), and reduce niters by 100x to 12/UNROLL, I get (with dyn alloc and OpenMP)

UNROLL=1 25.3s
UNROLL=2 25.4s
UNROLL=3 24.5s
UNROLL=4 24.3s

So it's about 3x slower than the small arrays.

If I increase it even more, by doubling k, I get (for 12/UNROLL to keep the divisors)

UNROLL=1 69.3s
UNROLL=2 66.5s
UNROLL=3 70.0s
UNROLL=4 68.1s

So about 5x slower than for small arrays

If I increase it even more, by increasing k with 4x, I get (for 12/UNROLL to keep the divisors)

UNROLL=1 159.5s
UNROLL=2 160.2s
UNROLL=3 175.6s
UNROLL=4 156.7s

So about 6x slower 

On FPGA this might be quite different. Maybe put a student on it?


* Run the script `./aux/gen_macros_cfg_SConstruct.pl $UNROLL` to generate `macros.h` and `SConstruct` in `./src` and `rf4a_{UNROLL}` in `.`.
	* Starts from the code in src/
	* The file `macros.h` defines the UNROLL macro

		test it:

			scons
			./test_sor_unroll_{UNROLL}

* In `src`, run `run_cpp.pl -o ../src_{UNROLL}_postcpp/`

		test it:

			cd ../src_{UNROLL}_postcpp/
			cp ../src/SConstruct .
			scons
			./test_sor_unroll_{UNROLL}

* In the main directory:
	* Running `refactorF4acc.pl -c ./rf4a_{UNROLL}.cfg`  will create an inlined version in `refactored-src_{UNROLL}/src_{UNROLL}_postcpp`
	* ( The `rf4a_{UNROLL}.cfg` file is generated by `gen_macros_cfg_SConstruct.pl`)

* Generate the `SConstruct` in `refactored-src_{UNROLL}/src_{UNROLL}_postcpp` by running `./aux/gen_SConstruct_refactored.pl $UNROLL`.
* In `refactored-src_{UNROLL}/src_{UNROLL}_postcpp`:
	* Build and test

			scons
			./test_sor_unroll_{UNROLL}

	* Run `../../aux/run_autoparallel_compiler_GPU.sh UNROLL`. This creates the module in `./autopar_{UNROLL}`
	* In `autopar_{UNROLL}`, patch the module file to change `get_global_id()` calls to `global_id` arguments: run `../aux/patch_autopar_superkernel_src.pl`
	* NOTE: this also removes the substring 'superkernel_' because the memory reduction pass relies on a single superkernel.
	* NOTE: it is essential to remove the temp arrays from the superkernel argument list. This is what we should use 'Purpose' for.
	* In `patched_autopar_{UNROLL}`, run  `memory_reduction.pl -C`, then the inliner etc.
		* In `MemoryReduction/Generated`, test the code:

				scons
				./gen_sor_superkernel

		* Inline the code:
			- Generate the config file with `../aux/gen_cfg_inline.pl $UNROLL` if required
			- In `MemoryReduction`, run `refactorF4acc.pl -c rf4a_inline_$UNROLL`
	* In `patched_autopar_{UNROLL}/mem_reduced_inlined/Generated`, run  `../../../aux/patch_inlined_code.pl $UNROLL`
		- That should provide the final code in `patched_autopar_{UNROLL}/mem_reduced_inlined/Generated/Patched`



